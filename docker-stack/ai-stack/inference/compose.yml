version: "3.8"

services:
  xinference: &xinference
    image: xprobe/xinference:latest-cu128
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              count: all
    volumes:
      - ${APPDATA}/data/:/root/.xinference
      - modelscope-cache:/root/.cache/modelscope
    environment:
      - PUID=0
      - PGID=0
      - XINFERENCE_MODEL_SRC=modelscope

  xinference-supervisor:
    <<: *xinference
    ports:
      - "9997:9997"
      - "9999:9999"
    command: xinference-supervisor --host xinference-supervisor --port 9997 --supervisor-port 9999
    restart: unless-stopped

  tts-worker:
    <<: *xinference
    ports:
      - "30001:30001"
    command: xinference-worker -e http://xinference-supervisor:9997 --host tts-worker --worker-port 30001
    restart: unless-stopped

  stt-worker:
    <<: *xinference
    ports:
      - "30002:30002"
    command: xinference-worker -e http://xinference-supervisor:9997 --host stt-worker --worker-port 30002
    restart: unless-stopped

  rerank-worker:
    <<: *xinference
    ports:
      - "30003:30003"
    command: xinference-worker -e http://xinference-supervisor:9997 --host rerank-worker --worker-port 30003
    restart: unless-stopped

  chat-worker:
    <<: *xinference
    ports:
      - "30004:30004"
    command: xinference-worker -e http://xinference-supervisor:9997 --host chat-worker --worker-port 30004
    restart: unless-stopped

  embed-worker:
    <<: *xinference
    ports:
      - "30005:30005"
    command: xinference-worker -e http://xinference-supervisor:9997 --host embed-worker --worker-port 30005
    restart: unless-stopped

volumes:
  modelscope-cache:
